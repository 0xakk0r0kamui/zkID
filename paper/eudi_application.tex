% \jbel{Links to read (we can basically copy paste a lot from these):
% \begin{itemize}
% \item EUDI ARF (full) \href{https://eu-digital-identity-wallet.github.io/eudi-doc-architecture-and-reference-framework/latest/}{here}
% \item Discussion of Google/Microsoft pros/cons \href{https://github.com/eu-digital-identity-wallet/eudi-doc-standards-and-technical-specifications/blob/main/docs/technical-specifications/ts4-zkp.md}{here}
% \item Google's IETF draft for libZK \href{https://www.ietf.org/id/draft-google-cfrg-libzk-00.html#name-sumcheck}{here}
% \end{itemize}}

% Why should EUDI consider this report?
% \begin{itemize}
%     \item Does it compatible with current EUDI decision like data format and ecosystems?
%     \item Why governments or organizations should choose this scheme?
%     \item \textbf{Our pros and cons are already shown in other sections, so just mentioned them when we need them in this section}
% \end{itemize}

Our report is highly relevant to the EUDI's initiatives and demonstrates another viable solution to adding programmable zero-knowledge proofs around digital credential presentation. 
This section is structured according to \href{https://github.com/eu-digital-identity-wallet/eudi-doc-architecture-and-reference-framework/blob/main/docs/discussion-topics/g-zero-knowledge-proof.md}{Topic G} in the EUDI ARF discusssion threads.

\paragraph{Issuance.} PID Providers or Attestation Providers would remain oblivious to the use of this scheme, and therefore no changes to the issuance process would be required (which would potentially be very expensive).
Our solution can handle any of the intended credential data standards (SD-JWT and mDL with standard \href{https://mobiledl-e5018.web.app/ISO_18013-5_E_draft.pdf}{ISO/IEC 18013-5}), 
as mentioned in \href{https://eu-digital-identity-wallet.github.io/eudi-doc-architecture-and-reference-framework/1.4.0/annexes/annex-2/annex-2-high-level-requirements/}{Annex 2} of the EUDI Architecture Reference Framework.
Furthermore, due to the generic nature of programmable zkSNARKs, it would be very easy to adapt to any changes in the Issuer's signature scheme in the future (e.g. switching to post-quantum signature schemes) will be easy to take into consideration;
we would simply modify our zkSNARK circuit to reflect the computation of a new signature verification, without having to come up with a new ad-hoc protocol for a specific signature scheme.  

\paragraph{Efficiency.} Governments should choose this scheme for its [potential] efficiency due to the nature of how we split up the proofs â€“ by a fixed relation and by a live, presentation-specific relation.
[TODO: insert concrete benchmarks when we have them].
Our scheme is also highly modular; one can swap out Spartan for another zkSNARK system that uses polynomial commitment schemes in a modular form, and one can also swap out the polynomial commitment scheme. 
The benefit of choosing a modular approach is that it is relatively easy to update on future innovations for proof systems that make them more efficient.

\paragraph{Discussion.} While our scheme is not yet post-quantum secure, its modularity means that it will be relatively easy to swap in modified Ajtai lattice-based commitments as presented by Hwang, Seo, and Song \cite{cryptoeprint:2024/306}.
Some components of our scheme are not yet standardized. However, the other solutions under consideration from Google and Microsoft also use unstandardized cryptography, and arguably ``more unstandardized'' cryptography. 
In particular, we do not make any strong assumptions, such as the pairing-based assumptions that Microsoft makes.
Our zkSNARK uses a Spartan backend, which relies only on the sumcheck and Pedersen commitments.
Sumcheck is a folklore protocol with information-theoretic security that does not rely on cryptographic assumptions, and Pedersen commitments have been used since 1991 \cite{C:Pedersen91} and only rely on the discrete-log assumption, which standardized ECDSA signatures already rely on. 

Finally, our team is also actively working on zkSNARK standards, and we believe the long-term solution is not to avoid unstandardized cryptography, but to argue the need for such cryptography in these applications and push forward the corresponding standards. 

